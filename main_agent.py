import os
from pathlib import Path
from typing import List, Optional, Dict, Any
from pydantic import BaseModel, Field
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.output_parsers import PydanticOutputParser
from langchain_core.prompts import ChatPromptTemplate, FewShotPromptTemplate, PromptTemplate
import json
import getpass

if "GOOGLE_API_KEY" not in os.environ:
    os.environ["GOOGLE_API_KEY"] = getpass.getpass("Enter your Google AI API key: ")

class ArticleOutput(BaseModel):
    markdown: str = Field(description="The article content converted to markdown format")
    json_metadata: dict = Field(description="Metadata about the article in JSON format")
    user_queries: List[str] = Field(default_factory=list, description="List of queries needed from the user")

class Example(BaseModel):
    input: str
    markdown_output: str
    json_output: dict

def load_examples() -> List[Dict[str, Any]]:
    """
    Load example files to use for few-shot learning.
    Expects .txt files for input and corresponding .md and .json files for output.
    """
    example_names = [
        "nomacs-image-viewer",
        "fontPreviewer"
    ]
    
    examples = []
    for name in example_names:
        txt_path = Path(f"data/{name}.txt")  # Original article text
        md_path = Path(f"data/{name}.md")    # Processed markdown
        json_path = Path(f"data/{name}.json") # Metadata
        
        if all(p.exists() for p in [txt_path, md_path, json_path]):
            with open(txt_path, 'r', encoding='utf-8') as f:
                original_text = f.read()
            with open(md_path, 'r', encoding='utf-8') as f:
                md_content = f.read()
            with open(json_path, 'r', encoding='utf-8') as f:
                json_content = f.read()
                
            examples.append({
                "input": original_text,            # Use original text as input
                "markdown_output": md_content,     # Use processed markdown as output
                "json_output": json_content        # Use metadata as output
            })
        else:
            missing_files = [p for p in [txt_path, md_path, json_path] if not p.exists()]
            print(f"Warning: Missing files for example '{name}': {missing_files}")
    
    if not examples:
        raise ValueError("No complete examples found. Each example requires .txt, .md, and .json files.")
    
    return examples

def create_prompt_template(article_date: Optional[str] = None) -> FewShotPromptTemplate:
    """Create a FewShotPromptTemplate with example formatting."""
    
    # Define how each example should be formatted
    example_template = """
Original article:
{input}

Processed markdown:
{markdown_output}

Generated metadata:
{json_output}
"""
    example_prompt = PromptTemplate(
        input_variables=["input", "markdown_output", "json_output"],
        template=example_template
    )
    
    # Create the prefix (system prompt)
    prefix = """You convert articles to markdown and json pairs. Here are some examples of the expected input and output format.

        Your response must be a valid JSON object with the following required fields:
        1. "markdown": a string containing the article in markdown format
        2. "json_metadata": an object with metadata keys
        3. "user_queries": a list of strings (can be empty if no queries are needed)

        For the markdown:
        - Retain the same words, details, and context length.
        - Add markdown formatting (#,*, ```, etc) and marks to make it suitable for a blog post.
        - Avoid starting a line with an English character unless it's the same in original text.
        - If the article mentions something in a comment, note this as a query.
        - Remove any lines asking for comments.
        - Replace article references with "link to be added", don't replace other links.
        - Do NOT start the md file with the title, just start with the same words in the original text.

        For the json_metadata object, include these keys:
        {{{{
            "title": "",
            "image": "",
            "description": "",
            "date": "{date}",
            "author": ""
        }}}}

        Extract values from the article if available. Use the provided date if given, or an appropriate date format if not.
        If title and description aren't explicitly mentioned, create them based on the article content.

        **THE ARTICLE SHOULD BE WRITTEN IN ARABIC, KEEP THE ORIGINAL TONE**"""
    if article_date:
        prefix = prefix.format(date=article_date)
    else:
        prefix = prefix.format(date="")
        
    # Create suffix (the actual task prompt)
    suffix = """
Now, process the following article:
{input}

Provide the markdown content and JSON metadata in the required format."""

    # Load and format examples
    examples = load_examples()
    
    # Create the FewShotPromptTemplate
    few_shot_prompt = FewShotPromptTemplate(
        examples=examples,
        example_prompt=example_prompt,
        prefix=prefix,
        suffix=suffix,
        input_variables=["input"],
        example_separator="\n\n---\n\n"
    )
    
    return few_shot_prompt

def process_article(article_text: str, article_date: str = None):
    """Process an article using few-shot learning approach."""
    # Initialize the LLM
    llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash")
    
    # Create the prompt template
    few_shot_prompt = create_prompt_template(article_date)
    
    # Create the output parser
    output_parser = PydanticOutputParser(pydantic_object=ArticleOutput)
    
    # Create the chain
    chain = few_shot_prompt | llm | output_parser
    
    # Run the chain
    result = chain.invoke({"input": article_text})
    return result

def save_files(output: ArticleOutput, base_filename: str) -> tuple[Path, Path]:
    """Save the processed output to files."""
    output_dir = Path("output")
    output_dir.mkdir(exist_ok=True)
    
    markdown_path = output_dir / f"{base_filename}.md"
    with open(markdown_path, "w", encoding="utf-8") as f:
        f.write(output.markdown)
    
    json_path = output_dir / f"{base_filename}.json"
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(output.json_metadata, f, ensure_ascii=False, indent=2)
    
    return markdown_path, json_path

# Example usage
if __name__ == "__main__":
    sample_article = """
    ุงูููุฏูุง ูู ูุงู ุณุงุนุฉ ุฃุนููุช ุนู ูุฑูุช RTX 50ุ ูู ุงูุจูุณุช ุฏู ููุถุญูู ุดููุฉ ุญุงุฌุงุช ุนุดุงู ูุชุชุบููุด ูููุงู ูุดุฑุญูู ุงูู ุงูุฌุฏูุฏ ูุงูู ุงููู ุงูููุฑูุถ ุชูุชู ุจูู.
ูู ูุนุงู ุฃู ูุงุฑุช ูุฏูู ูู ูุฑูุช RTX ูููู ุงูุจูุณุช ุฏู ูููู ุจุฑุถู
ุงูุฃูู ูุชููู ุดููุฉ ุนู DLSS 4
ุฒู ูุง "ุทูุจ ุงูุฃุฑุถ" ูุงู ูุชููุนุ ุงูููุฏูุง ุนููุช Frame Generation ุนู ุทุฑูู ุงูู Extrapolation ุจุฏู ุงูู Interpolation.
ูุนูู ุงูุฃูู ูุงูุช ุงูุชูููุฉ ุฏู:
ุจุชุฑูุฏุฑ ุงููุฑูู ุงูุญุงูู ููููู ูุฑูู ุฑูู 1 ูุชุนุฑุถู ุนูู ุงูุดุงุดุฉ (ูุฏุฉ ูุฑูู 1 ูุนุฑูุถ ุฎูู ุจุงูู)ุ ุซู ุชุฑูุฏุฑ ุงููุฑูู ุงูุฌุงู ุงููู ูู ุฑูู 2 ูู ุบูุฑ ูุง ูุชุนุฑุถ ุนูู ุงูุดุงุดุฉุ ูุจุนุฏูู ุชุนูู ูุฑูู ุจูููู ูุจูู ุฑููู 1.5 ูุซูุงูุ ุซู ุชุนุฑุถ ุงููุฑูู 1.5 ุงููู ูู ุนููุชู ุฏูุ ุซู ุชุนุฑุถ ุงููุฑูู 2ุ ูุชุณุชูุฑ ุงูุนูููุฉ ุฏู ุนูู ุทูู.
ุฏู ูุงู ุจูุนูู ูุดููุฉ ูุงุถุญุฉ ุฌุฏุงูุ ุฅู ุงุณุชุฌุงุจุฉ ุงููุนุจุฉ ุจุชุจูู ุจุทูุฆุฉ/ุชูููุฉ ุญุชู ูู ุดูููุง smoothุ ูุฏู ุนุดุงู ุงูุชูููุฉ ูุญุชุงุฌุฉ ุชุฃุฎุฑูู ุนุฑุถ ุงูุดุงุดุฉ ุนูุจุงู ูุง ุชุนูู ูุฑููุงุช ูุณูุทุฉ.
ุงูุฌุฏูุฏ ุจูู:
ุฅู ุงูุชูููุฉ ุฏู ุจููุช ุจุชุฑูุฏุฑ ูุชุนุฑุถ ูุฑูู 1 ูุชุฑูุฏุฑ ูุชุนุฑุถ ูุฑูู 2 ุนุงุฏู ุฌุฏุงู
ุซู ุชูุชุฌ ูุฑูู 3 ุนู ุทุฑูู ุงูุชูุจุค ุจูู!
ูุนูู ูู ุบูุฑ ูุง ุชุนูู ุญุณุงุจุงุช ุงูุฅุถุงุกุฉ ูู ุชุงูู ููุง ุชุนูู ุญุณุงุจุงุช ุงูููุฒูุงุก ููุง ุฃู ุญุงุฌุฉ
ูุฌุฑุฏ ุชุดูู ุขุฎุฑ ูุฑูููู ูุชุชููุน ุงูุชุงูุช ุดููู ุนุงูู ุงุฒุงู (ุฏู ุญุงุฌุฉ ุจุฏูููุฉ ุฃูู ูุนูู ูุนุฑูุด ุฅูู ุงููู ุฃุฎุฑูู ูุฏุฉ ุจุตุฑุงุญุฉ ๐ญ)
--
ูุฑูุช RTX 50 ูููุง ูุชูุฏุฑ ุชูุชุฌ ุนุฏุฏ ูุจูุฑ ูู ุงููุฑููุงุช ุนู ุทุฑูู ุงูู Frame Generation (ุงูููุฏูุง ุจุชููู 3 ุฅูุชุงุฌ ู1 ุญุณุงุจ ููู 4 ูุฑููุงุช ูุนุฑูุถุฉ ุนุงูุดุงุดุฉ)
ุงูููุฏูุง ุจุชููู ุฅููู ุนูููุง ุชุนุฏูู ูู ุงููุงุฑุฏููุฑ ุจุชุงุน ุงูู FG ุนุดุงู ูุฎููู ููุฏุฑ ููุชุฌ ูุฑููุงุช ูุชูุฑุฉ ุจุญุณุจุฉ ูุงุญุฏุฉ ุจุณุ ูุงููู ุงุณุชุจุฏููุง ูุญุฏุฉ ุญุณุงุจ ุงูููุดู ูููุชูุฑุฒ ุจููุฏูู AI ูุดุชุบู ุนูู ุงูู tensor cores.
ูุฑูุช RTX 40 ูุณุจุช ููุณ ุงูููุฒุฉ ุจุฑุถู ุจุณ ูุชูุฏุฑ ุชูุชุฌ ูุฑูู ูุงุญุฏ ุจุณ ูู ุงููุณุชูุจู ูุด ุชูุงุชุฉ.
ุงูููุฏูุง ุจุชููู ุงููู ุญุงูููุง ูุฎููู ููุชุฌ ุฃูุชุฑ ูู ูุฑูู ููู ุงููุงุฑุฏููุฑ ุจุชุงุนู ูุญุชุงุฌ ูุนูู ุญุณุจุฉ ุงูููุดู ูููุชูุฑุฒ ูู ูุฑุฉ ููุชุฌ ูููุง ูุฑูู ุฌุฏูุฏ ุนุดุงู ูุฏุฉ ูู ุฒูุฏูุง ุนุฏุฏ ุงููุฑููุงุช ุงูุขุฏุงุก ููุจูู ุฃูู ูู ููุง ุชุทูู ุงูุฎุงุตูุฉ ุฎุงูุต ๐.
ูุฑูุช 30 ู 20 ูููููุด ุญุงุฌุฉ ูู ุงูู Frame Generation ๐
ุจุณ ุฎุงุตูุฉ DLSS ูุงููุฉ ุนูู ูู ุงููุฑูุช ูุชุณุชูู ููุฏููุงุช ุฌุฏูุฏุฉ ูุชุดุชุบู ุนูู ุฃู ูุนุจุฉ ูููุง DLSS
ุงูููุฏูู ุงูุฌุฏูุฏ ูุนููู ุจู Transformer Architecture ุจุฏู ุงูู CNN
ุฃููุฉ ุชุฑุงูุณููุฑูุฑ ุฒู ุดุงุช ุฌูุจูุชู ูุฏุฉ ๐คฃ
ููุฒุชู ุงูู ุจููุฏุฑ ูุดูู ุงูุตูุฑุฉ ูููุง ููุฑุจุท ุงูุชูุงุตูู ุจุจุนุถุ ุนูู ุนูุณ ุงูู CNN ุงููู ุจูุนุงูุฌ ูู ุฌุฒุก ูู ุงูุตูุฑุฉ ููุญุฏู
ุฌูุฏุชู ุงูููุฑูุถ ุชููู ุฃูุถู ุจูุชูุฑ ุฌุฏุงู ูู ุงูุฃูู ูุงูููุฑูุถ ูุฎูุตูุง ูู ุงููุงุฒููู ุงููู ุงูุฃูุนุงุจ ุจุชุฏูู ุจูู ุงูุดุงุดุฉ ุงูููููู ุฏูู.
ููุงู ููุจูู ุนูุฏู ุงููุฏุฑุฉ ุชุณุชุจุฏู ุงูู DLSS ุงููุฏูู ุจุงูุฌุฏูุฏ ุนู ุทุฑูู ุฃุจูููุดู ุงูููุฏูุง ูู ุฃู ูููุง DLSS.
----------------
ููุฌู ุจูู ููููู ุฃููุ ุงูููุฏูุง ุจุชููู ุงู ุงูู RTX 5070 ููููู ุจุณุนุฑ 550 ุฏููุงุฑ ุจุณ ููุฏูู ุขุฏุงุก ูุฏ ุงูู 4090!
ุฏู ููุงู ูุถูู ุดููุฉุ ูู ููุฏูู ุงูุขุฏุงุก ุฏู ูุนูุงู ููู ุจุงูู DLSS FG ุนู ุทุฑูู ุงูู ูุนูู 3 ูุฑููุงุช ุฃู ุฃูุชุฑ ูู ุงูููุง ููุฑูุฏุฑ ูุฑูู ูุงุญุฏ ุญูููู.
ุชูุฏุฑ ุชุชุฃูุฏ ูู ุงูููุงู ุฏู ุนู ุทุฑูู ุงูุฌุฑุงู ุงููู ูุดุฑูู
ุดูู ุงูููุงุฑูุฉ ุจูู ุงูู 5090 ูุงูู 4090ุ ูุชูุงูู ุงูุฒูุงุฏุฉ ูู ูุนุจุฉ Far Cry 6 ุงููู ูุทูู ูููุง ุงูู DLSS ุชูุฏุฑ ุจุญูุงูู 20% ุจุณ.
ูุฐูู ูู ูู ุงููุฑูุช ูุชูุงูู ุงูุฒูุงุฏุฉ ุจูู ุงูุฌูู ุงููู ูุงุช ูุงูุฌุฏูุฏ ูู 20% ูู 30% ุจุณ.
ูู ุงูู AI ุงููุตุฉ ูุฎุชููุชุด ูุชูุฑ
ูู ุจุตูุช ุนุงูุฌุฑุงู ูุชูุงูู ุขุฏุงุก Flux ุฃุนูู ุจู 2X ูู ุงูุฌูู ุงููู ูุงุช!
ููู ุฏู ููุงู ูุถูู ุจุฑุถู ูุฅูู ูู ุจุตูุช ุชุญุช ุนูู ุงูููุช ุจุฑูุช ูุชูุงูู ุฅู ุงูููุฏูู ุดุบุงูุฉ ุจูุตู ุฏูุฉ ุงูุญุณุงุจุงุช ุนูู ุงูู RTX 5090 ุงููู ูู fp4ุ ุจุฏู fp8 ุนูู ุงูู 4090.
ุฏู ูููุฑู ุฌุฏุงู ูู ุงูุขุฏุงุก ูุงุณุชููุงู ุงูุฑุงู ููููุฉ ุงูุญุณุงุจุงุช ููู ุญุงุฌุฉุ ุทุจุนุงู ูููุฑู ูู ุงููุชูุฌุฉ ููุงู ูุจุงูุชุงูู ูุด ููุฏูู ููุณ ุชูุงุตูู ุงูุตูุฑ ููุง ูุฑูุจ ูููุง ุญุชู.
ุงูู VRAM ููุชุฉ ููุณูุจูุง ูููู ุชุงูู ุจุณ ูููู ูููุฉ ุตุบูุฑุฉุ ุงูููุฏูุง ุนููุช ุญุชุฉ ููุฏูู ุตุบููู ูุธููุชู ูุถุบุท ุงูุฏุงุชุง ุจุชุงุนุช ุงููุนุจุฉ ูู ุงูู vramุ ุงููุจูุฑ ุฅู ุงูููุฏูู ุฏู ุนูุฏู ุงููุฏุฑุฉ ูุนุงูุฌ ุงูุฏุงุชุง ุฏู ููู ูุถุบูุทุฉ! ุฏู ุญุงุฌุฉ ุฃูู ูุฑุฉ ูุดูููุง ุนูููุงู ุจุณ ูุงุฒู ูุดูู ูุชุงูุฌูุง ุจุนุฏูู ูุจู ูุง ูููู ุญุงุฌุฉ.
ุชูุตููุฉ ุฅุถุงููุฉ ุชุงููุฉุ ุจูููููุง ุดุบุงููู ุนูู ุชูููุฉ Reflex 2 Frame warpุ ูููุด ุชูุงุตูู ุนููุง ุจุณ ุงูุธุงูุฑ ุงููุง ูุชุบูุฑ ุงููุฑูู ุจุนุฏ ูุง ูุชุฑูุฏุฑ ุนุดุงู ูุฏูู ุขุฎุฑ ุญุฑูุฉ ุจุนุชูุง ุงููุงูุณ ูุจู ูุง ุงููุฑูู ููุตู ููุดุงุดุฉ.
ุนูููุงู ุฃูุง ููุช ูุชููุน ุญุงุฌุงุช ูุนููุฉ ูุจูุฑุฉ ุฃูุชุฑ ูู ูุฏุฉ ุจุณ ุดูููุง ูุณุฉ ูู ุงููุทุจุฎ ููุญุชุงุฌุฉ ุชุณุชูู ุดููุฉ ููุงู
ูู ุญุฏ ูุด ูุงูู ุญุงุฌุฉ ุงูููููุชุงุช ููุชูุญุฉ ุฎุฏ ุฑุงุญุชู ูุงุณุฃู
ูุงูุณูุงู ุนูููู
    """
    
    result = process_article(sample_article, "2023-01-10")
    md_path, json_path = save_files(result, "ai_article")
    
    print(f"Markdown saved to: {md_path}")
    print(f"JSON saved to: {json_path}")
    
    if result.user_queries:
        print("\nQueries for user:")
        for query in result.user_queries:
            print(f"- {query}")